<!DOCTYPE html>
<html>
<head>
  
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.4"> </script> 

 

<textarea type="text" id="myText01" rows="10" cols="60" wrap="false"></textarea><br>

Batches <input id="myInNumber" type="number" value="3000"> 
 
<input id="myButton4949" type="button" value="Tensorflowjs xOr using layers" onclick="{
 const startTime2 = new Date().getTime()
 document.getElementById('myDiv4949').innerHTML = '<br>'
 document.getElementById('myButton4949').style.backgroundColor = 'red'  
                                                                            
                                                                            
  async function myGo() {
    model4949 = tf.sequential(); // make it global


    model4949.add(tf.layers.dense({ units: 3, name: 'hiddenLayer',  activation: 'sigmoid' , inputShape: [2] }) );  
    model4949.add(tf.layers.dense({ units: 1, name: 'outputLayer', activation: 'sigmoid' }) );    
                                        
    model4949.compile({loss: 'meanSquaredError', optimizer: 'rmsprop'});

    const training_data = tf.tensor2d([[0,0],[0,1],[1,0],[1,1]]);   // array defines shape
    const target_data = tf.tensor2d([0,1,1,0],[4,1]);               // needs shape defined

  //  var h = await model.fit(training_data, target_data, {epochs: document.getElementById('myInNumber').value});

										     
    for (let myLoop = 1; myLoop <= document.getElementById('myInNumber').value; myLoop++) {                                                                                 
        var myFit = await model4949.fit(training_data, target_data, {epochs: 1});
        if (myLoop % 100 == 0){   
             await tf.nextFrame();   // This allows the GUI to update but only every 100 batches      
             document.getElementById('myDiv4949').innerHTML  =  'Loss after Batch ' + myLoop + ' : ' + myFit.history.loss[0].toFixed(5) +'<br><br>'                                                                           
        }
                                                                   
    }										     
										     
										     
										     


    const myPredictArray = await model4949.predict(training_data).data()
                                                                                    
    document.getElementById('myDiv4949').innerHTML += '[0,0] = ' + myPredictArray[0].toFixed(4) +'<br>'
    document.getElementById('myDiv4949').innerHTML += '[1,0] = ' + myPredictArray[1].toFixed(4) +'<br>'
    document.getElementById('myDiv4949').innerHTML += '[0,1] = ' + myPredictArray[2].toFixed(4) +'<br>'
    document.getElementById('myDiv4949').innerHTML += '[1,1] = ' + myPredictArray[3].toFixed(4) +'<br>'
										     
    const endTime2 = new Date().getTime()
    document.getElementById('myDiv4949').innerHTML += 'Duration ' + ((endTime2-startTime2)/1000).toFixed(0) +' seconds <br>'											     
										     
    document.getElementById('myButton4949').style.backgroundColor = 'lightgray'                                                             
    myWeights = []
    myWeights = model4949.getWeights()
//myWeights[0].print('verbose')
 //   myWeights[1].print('verbose')
 //   myWeights[2].print('verbose')
 //   myWeights[3].print('verbose')
    document.getElementById('myText01').value = myWeights
   
										     
										     
  }

  setTimeout(function(){  myGo() }, 10);   // wait a bit for the GUI to update

}"><br><br>
Local or Download file name <input type="text" id="myFileName" value="my-file-model-01"> 
DON'T CHANGE THIS FILE NAME WHEN SAVING TO COMPUTER AS IT NAMES THE WEIGHTS FILE RELATIVE PATH! 	<br>	
	
	
	
	
	
<input id="myLocal5858" type="button" value="Save to local storage" onclick="{
   ( async function (){									    
       const saveResults = await model4949.save('localstorage://'+document.getElementById('myFileName').value)								    
       alert(JSON.stringify(saveResults))
   })()  // inline async function									    
}">
	
<input id="myFile5858" type="button" value="Save to downloads" onclick="{	
   ( async function (){									    
          const saveResults2 = await model4949.save('downloads://'+document.getElementById('myFileName').value);							    
          alert(JSON.stringify(saveResults2))
   })()  // inline async function								     
}"><br>	
	
	
<input id="myFile5858" type="button" value="View Saved local storage" onclick="{	
   ( async function (){									    
 
	 document.getElementById('myDiv4949').innerHTML = Object.keys(await tf.io.listModels())							
								
								
   })()  // inline async function								     
}">  View file system saved files <input type="file" size="80"> <br>	
	
	
<br><br>

<div id='myDiv4949'>...</div><br>  
  
  
  
  
  
<script>
var isPhoneGapWebView = location.href.match(/^file:/); // returns true for PhoneGap app
  
if (isPhoneGapWebView){
  // document.writeln('<h1>I am cordova</h1>')

} else{
  // document.writeln('<h1>I am a web browser</h1>')
} 
  

  
</script>  
  
<script src="face-api.js"></script>
  
  
  
</head>
<body>
  <div id="myDiv02">...</div><br>  

<div id="myDiv01">...</div><br>  
    
  
<input type=button style="font-size:25px;" value=" run " onclick="{
    run()
}">  
  
<input type=button style="font-size:25px;" value="switch to environment" onclick="{
   if (this.value == 'switch to environment'){                                                       
       myCamera = 'environment'
       this.value = 'switch to user' 
    } else {                                                      
       myCamera = 'user'
       this.value = 'switch to environment'                                                     
    }                                                         
    videoEl.srcObject.getTracks().forEach(track => track.stop()) 
    run()        
}">    
  
<input type=button style="font-size:25px;" value=stop onclick="{
   videoEl.srcObject.getTracks().forEach(track => track.stop()) 
}"><br> <br>
  
  
  <input type=button style="font-size:25px;" value=" new " onclick="{

}"><br> <br> 
  
  
<div id="myVideoDiv" onclick="{
 alert('you clicked the video')                             
                              
}">   
  <video onplay="onPlay(this)" id="inputVideo" autoplay muted  width="640" height="480" style=" border: 1px solid #ddd;"></video><br>
  <canvas id="overlay" width="640" height="480" style="position:relative; top:-487px; border: 1px solid #ddd;" ></canvas><br>
</div>  
  

  
  
    <h3 align=center>face-api.js by <a href="https://github.com/justadudewhohacks/face-api.js">@justadudewhohack</a> 
    simplified for beginners by <a href="https://www.rocksetta.com/tensorflowjs/">@rocksetta</a></h3>
  The <a href="https://github.com/hpssjellis/face-api.js-for-beginners">github is here</a><br>  
  
  
</body>

<script>


////////////////////////// Globals ///////////////////////////////////////////     
  
let stream  
let myCamera = 'user'  
const videoEl = document.getElementById('inputVideo')  
  
////////////////////////// A few helper functions ///////////////////////////////////////////   
   
function myOrient(){  // not using anymore
   if(window.orientation == 0){
       // portrait
      document.getElementById('inputVideo').width = 480
      document.getElementById('inputVideo').height = 640    
      document.getElementById('overlay').width = 480
      document.getElementById('overlay').height = 640  
      document.getElementById('overlay').style.top = '-647px'
   } else {
        // lanscape default working   
      document.getElementById('inputVideo').width = 640
      document.getElementById('inputVideo').height = 480 
      document.getElementById('overlay').width = 640
      document.getElementById('overlay').height = 480 
      document.getElementById('overlay').style.top = '-487px'
   }  
}  
  
  
  
  
  
  
  
window.addEventListener("orientationchange", function() {
  // myOrient()
   videoEl.srcObject.getTracks().forEach(track => track.stop()) 
   run() 
   // if(window.orientation == 0){document.getElementById('myDiv02').innerHTML = '<h1>Portrait</h1>'} else {document.getElementById('myDiv02').innerHTML = '<h1>Landscape</h1>'}   
}, false);
  
   
  
function resizeCanvasAndResults(dimensions, canvas, results) {
  const { width, height } = dimensions instanceof HTMLVideoElement
    ? faceapi.getMediaDimensions(dimensions)
    : dimensions
    canvas.width = width
    canvas.height = height

  return results.map(res => res.forSize(width, height))
}

  
function drawDetections(dimensions, canvas, detections) {
  const resizedDetections = resizeCanvasAndResults(dimensions, canvas, detections)
  faceapi.drawDetection(canvas, resizedDetections)
}

  
function drawLandmarks(dimensions, canvas, results, withBoxes = true) {
  const resizedResults = resizeCanvasAndResults(dimensions, canvas, results)
  if (withBoxes) {
      faceapi.drawDetection(canvas, resizedResults.map(det => det.detection))
  }
  const faceLandmarks = resizedResults.map(det => det.landmarks)
  const drawLandmarksOptions = { lineWidth: 2, drawLines: true, color: 'green' }
  faceapi.drawLandmarks(canvas, faceLandmarks, drawLandmarksOptions)
}    
    

  
////////////////////////// The 2 Main functions ///////////////////////////////////////////  
  
async function onPlay() {

   const videoEl = document.getElementById('inputVideo')
   const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold : 0.3 }) 

   
   result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks(true)
   if (result) {
       drawLandmarks(videoEl, document.getElementById('overlay'), [result], true)
     
      // Just printing the first of 68 face landmark x and y 
      document.getElementById('myDiv01').innerHTML = 'First of 68 face landmarks, x: '+ 
        Math.round(result._unshiftedLandmarks._positions[0]._x) + ', y: '+ 
        Math.round(result._unshiftedLandmarks._positions[0]._y) +'<br>' 
        
   }

    setTimeout(() => onPlay())
}

async function run() {
  // myOrient()
   await faceapi.loadTinyFaceDetectorModel('https://hpssjellis.github.io/face-api.js-for-beginners/')
   await faceapi.loadFaceLandmarkTinyModel('https://hpssjellis.github.io/face-api.js-for-beginners/')
 
  if(window.orientation == 0){
      // portrait
      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: myCamera, width:480, height:640 }, audio: false}) 
  } else {
      // landscape
      stream = await navigator.mediaDevices.getUserMedia({video: { facingMode: myCamera, width:640, height:480 }, audio: false})
  }
   
   videoEl.srcObject = stream

}

</script>
</body>
</html>
